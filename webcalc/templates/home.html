<!-- templates/home.html -->
{% extends 'base.html' %}

{% block content %}
    <div style="padding:40px;margin:40px;border:1px solid #ccc">
        <h3> Welcome to the UCI Phonotactic Calculator! </h3>

        <h3><p style="color:red">This is a work in progress! If you notice any bugs or have any comments, please contact Connor Mayer at <a href="mailto:cjmayer@uci.edu">cjmayer@uci.edu</a>.</p></h3>

        <p>This is a research tool that allows users to calculate a variety of <i>phonotactic acceptability metrics</i>. These metrics are intended to capture how probable/acceptable a word is based on the sounds it contains and the order in which those sounds are sequenced. This is sometimes referred to as <i>phonotactic probability</i>, though we prefer the term <i>acceptability</i> because not all of the metrics employed here can be interpreted as probabilities. For example, a nonce word like [stik] 'steek' might have a relatively high phonotactic acceptability score in English even though it is not a real word, because there are many words that begin with [st], end with [ik], and so on. In Spanish, however, this word would have a low acceptability score because there are no Spanish words that begin with the sequence [st]. A sensitivity to the phonotactic constraints of one's language(s) is an important component of linguistic competence, and the various metrics computed by this tool instantiate different models of how this sensitivity is operationalized.</p>

        <p>The general use case for this tool is as follows:</p>
        <ol>
            <li>
                Choose a <i>training file</i>. You can either upload your own or choose one of the default training files (see the <a href="{% url 'about' %}">About</a> page for details on how these should be formatted and the <a href="{% url 'media' %}">Datasets</a> page for a description of the default files). This file is intended to represent the input over which phonotactic generalizations are formed, and will typically be something like a dictionary (a large list of word types). The models used to calculate the phonotactic acceptability metrics will be fit to this data.
            </li>
            <li>
                Upload a <i>test file</i>. The trained models will assign scores for each metric to the words in this file. This file may duplicate data in the training file (if you are interested in the scores assigned to existing words) or not (if you are interested in the predictions the various models make about how speakers generalize to new forms).
            </li>
            <li>
                Choose which <i>model</i> to use. Currently the calculator supports two suites of models.
                <ol>
                    <li>
                        <b>Unigram/Bigram scores</b>: this computes a suite of metrics that are based on unigram/bigram frequencies (that is, the frequencies of individual sounds and the frequencies of adjacent pairs of sounds). This includes type- and token-weighted variants of the positional unigram/bigram method from Jusczyk et al. (1994) and Vitevitch and Luce (2004), as well as type- and token-weighted variants of standard unigram/bigram probabilities.
                    </li>
                    <li>
                        <b>RNN Model</b>: this computes an acceptability metric based on the recurrent neural network phonotactic model from Mayer and Nelson (2020). Unlike the unigram and bigram models, which compute probabilities based on local dependencies, this model allows long distance restrictions such as vowel or consonant harmony to be effectively modeled.
                </ol>
                See the <a href="{% url 'about' %}">About</a> page for a detailed description of how these models differ and how to interpret the scores.
            </li>
        </ol>
        <p>
        The UCI Phonotactic Calculator was developed by <a href="http://connormayer.com">Connor Mayer</a> (UCI), Arya Kondur (UCI), and <a href="https://linguistics.ucla.edu/person/megha-sundara/">Megha Sundara</a> (UCLA). Please direct all inquiries to Connor Mayer (<a href="mailto:cjmayer@uci.edu">cjmayer@uci.edu</a>).
        </p>
        <h3>Citing the UCI Phonotactic Calculator</h3>

        <p>
        If you publish work that uses the UCI Phonotactic Calculator, please cite the GitHub repository:
        </p>
        <p>
        <blockquote>
        Mayer, C., Kondur, A., &amp; Sundara, M. (2022). UCI Phonotactic Calculator (Version 0.1.0) [Computer software]. https://doi.org/10.5281/zenodo.7443706
        </blockquote>
        </p>
        <!-- <object data = "/media/descriptions/home.txt" width = "100%" height = "250"></object> -->
    </div>

    <div style="padding:40px;margin:40px;border:1px solid #ccc">
        <h1>Provide Input for Calculations</h1>
        <h3 style="color:blue">Upload a training file or select a default file</h3>
        <form method="post" enctype="multipart/form-data">
        {% csrf_token %}
        {{ form.as_p }}
        {% if messages %}
          {% for message in messages %}
              <h3 style="color: red">{{ message }}</h3>
          {% endfor %}
        {% endif %}
        <button type="submit">Submit</button>
        </form><hr>
        <!-- <h3 style="color:green"><a href="{% url 'uploadDefault' %}">Use default training files instead</a></h3> -->
        
    </div>
{% endblock content %}